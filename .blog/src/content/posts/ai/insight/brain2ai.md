---
title: "从生物智能到人工智能"
description: "思考、对比和展望"
pubDate: "2025-02-24 15:22:00"
category: "dev"
banner: "@images/banners/banner-ai-bigbang.webp"
tags: ["dev", "doc", "geogebra"]
oldViewCount: 0
oldKeywords: []
---

# 从生物智能到人工智能

> 本文基于对生物智能和人工智能的联系与对比，展望一些有趣的探索方向。

## 智能的发展

生物智能是由生物体的大脑和神经系统组成的，生物体可以借助它来感知、学习、记忆、推理、决策和行动。生物智能是自然进化的产物，经过亿万年的演化，生物智能已经发展到了极高的水平。
- 化学反馈：单细胞生物通过化学物质的扩散来感知和移动。
- 神经网：感知环境并协调整个身体（多细胞生物）的复杂运动。
- 脊索：提供机械支撑和保护，集中信号传递，允许动物具有更大的体型。
- 中枢神经系统：整合感知信息，轴突长度增加支持长距离传输，更快和更复杂的反应。
- 大脑皮层：高度分化的神经元，支持更复杂精细的视觉，支持高级的认知功能。
- 人类大脑：足以发明语言这种非常抽象的表达能力，学会使用工具，发展出社会结构。

按照生物智能的发展过程，我们可以看出，不同智能特征的出现顺序如下：
- 反射
- 运动（精细控制）
- 视觉（高级）
- 语言
- 推理

看起来，语言其实是一种比较高级的智能活动，而视觉和运动其实要比语言更基础一些，推理则要更难一些。
- 语言是人类所特有的能力，如果人工智能想要达到人类的水平，就需要征服自然语言的理解和表达。
- 人工智能提供高级视觉能力和运动控制，所需的算力估计会比自然语言的理解与生成要少。
- 推理模型的建立是人工智能的终极目标，在语言模型的架构基础上可以发展出推理模型。

> 这解释了为什么人工智能的突破源自语言模型，也解释了推理模型和语言模型的发展关系。

## 智能的本质

从进化的角度看，生物智能实际上能让生物对环境做出预测，以提前做出趋利避害的反应，从而提高生存几率。因此，无论生物智能还是人工智能，它的结构所能带来的能力都应该可以对输入的环境信息做出一定的预测，并最终产生有利于服务某个特定目标的反馈。

现在比较流行的语言模型，其实就是一个预测模型，它的输入是一段文本，输出是这段文本的下一个词。如果我们问人工智能一个问题，人工智能所做的事情非常简单：那就是要预测紧跟着用户问题后的下一个词选哪个词最合适，选中当前词后在继续把问题和选出来的词再丢给模型去算再下一个词，如此循环往复，直到模型预测出一个结束符号。这个过程实际上就是一个预测的过程，也就是说，人工智能的本质是一个预测模型。人类大脑在处理语言的时候也是一样，我们在听别人说话的时候，会很自然的理解当前这句话的意思并猜想对方接下来可能会说什么，然后综合这些信息来做出回应。这个过程实际上也是一个预测的过程，也就是说，人类大脑的本质也是一个预测模型。虽然人类和计算机采用了不同的构造和机制来实现这个预测，但本质是一样的。

如果我们打破砂锅问到底，接下来很自然会想到，这种预测的本质又是什么？或者说，到底什么样的预测才能具有更高的智能？
- 记忆：对于学习阶段曾经掌握的历史性信息，可以近乎100%精准的预测
- 泛化：对于没有出现过的全新情况，可以通过掌握事物的模式和规律，达到较高水平的预测

所以，一个高水平的预测系统（智能），应该是对训练阶段的信息（学习资料），进行了某种深度的理解式记忆：不是查数据库的那种毫无加工的逐字逐句的死记硬背，而是掌握了这些信息背后的规律和模式，带有深刻分析和理解的记忆。我们也可以把这种理解式记忆，看成是一种追求极致效率的信息的压缩与还原。

假设我们能把全世界所有的知识都用文字写下来，再把它设法用理解式记忆压缩到一个算法模型里，然后任何时候我们只要向这个模型输入一个查询向量，这个模型就可以自动的把满足这个查询语义的最匹配的知识自动提取并输出，这个模型在我们人类看来就已经具备了智能。高水平的泛化预测需要对训练语料信息的完美压缩，而极致效率的压缩也必然会带来高水平的泛化预测。

> 智能的本质：通过对信息的极致压缩还原，而产生精确和泛化的预测。

## 智能计算的效率

虽然人工智能的爆发式增长令人瞩目，但说实话现在也还是刚刚开始，计算效率显然没有被充分优化，未来还有很大进步空间。于是，不少人看到天文数字的算力成本，可能会产生一个错觉，那就是人类的智能是非常高效的，而人工智能的效率则非常低下的。

作为一个进化论的坚定支持者，借鉴其它生命构造的进化水平，我却持有完全相反的观点：
- 生物智能其实是非常低效的，人工智能的计算效率可能已经高于生物智能（可预见的未来更会远超人类）。
- 生物智能具有很多的局限性，人工智能完全可以通过算法和硬件的调整克服这些局限性。
- 生物智能的进化太缓慢，而人工智能的进化则是一日千里，人工智能很快就可以全方位超越人类。

人脑的特点是体积小，只有1.5kg，而且耗能很低，只有20W，而且能干的事情很多，从运动、视觉到语言、推理，看起来的确效率非常高。人工智能单单推离都要花费价值百万的硬件，功率最低也要几千瓦，而且只能做一件事情（语言理解和生成），如果看训练更是动辄千万的训练成本，算力和能耗更是天文数字，看起来的确效率非常低。但这样去比，其实是不公平的，因为：
- 人工智能索引的知识几乎包含了整个互联网（历史快照），没有任何单一的人类大脑可以与之相比
- 人类的反应速度其实很慢，在最高性能的硬件上人工智能一秒钟可以吐字数万，哪怕最好的说唱歌手也不会超过十
- 虽然人工智能目前能力普遍比较单一（语言之外的能力稍显不足），但它具有相当不错的扩展潜力（多模态）

站在最细的粒度上，我们对比一下神经元的工作效率：
- 人脑的神经元的计算效率是每秒钟大约1万次，而且是模拟计算，计算效率非常低
- 人脑采用脉冲神经元，时序编码，并行和串行混合，人工神经元没有时序因素，只有并行计算
- 人工神经元之间信息传递取决于神经递质的活动，大致在毫秒级别，人工神经元则工作在纳秒级别

独立的看每一个神经元，人工神经元的计算效率要远高于生物神经元，所以真正的问题在于：
- 神经元之间的连接方式，其网络效率（尤其类似CNN的空间邻近性）可能导致实际计算规模有显著差异
- 人类大脑皮层的神经元是稀疏激活的，估计比例在1%左右，而即便是MoE模型也至少要激活5%的神经元
- 人类大脑其实没有特别长的上下文窗口（短期记忆），而对长距离依赖的支持可能是通过其它更高效的结构实现的；而人工智能目前流行的注意力机制，比较简单粗暴，计算复杂度太高

综合上面因素，生物智能和人工智能的计算效率眼下其实很难直接比较，毕竟各有不足，不过个人更看好人工智能的长期发展。

> 计算效率上，人工智能还有很大潜力可挖。

## 智能计算的硬件

区块链挖矿时代，英伟达就已经赚得盆满钵满。这次人工智能浪潮的破天富贵，更把英伟达抬升到了一个新的高度。但基于图形处理器的硬件方案真的就是最适合人工智能计算的硬件么？

生物智能和GPGPU的计算架构上有几个显著的不同。
- 生物智能的权重可以看成是某种模拟信号，而且是通过具有非线性时序特征某种脉冲神经网络来参与计算的。而GPGPU上运行的神经网络，是纯数字化的，FMA线性计算占比非常高。这一点看起来，可能应该是GPGPU的方案更优。
- 生物智能里的神经元是稀疏激活的，不同层的神经元之间也是稀疏连接的，而GPGPU上的神经网络是密集激活的。这一点看起来，可能应该是生物智能的方案更优。
- 生物智能的存储和计算是本地化的，也就是所谓的存算一体，而GPGPU架构里依靠数据总线和流水线调度的方式来实现存储和计算的分离。这一点看起来，可能应该是生物智能的方案更优。
- 生物智能的训练（更新权重）时，仿佛并不需要全局计算和优化，而只需要依赖局部信息。

现在断言TPU的终极形态还为时郭总，但一个比较理想的智能计算硬件架构，应该是：
- 本地化存算一体，模型的权重直接存储在神经元上，正向的推理计算也可以直接在神经元上进行
- 在神经元稀疏激活的状态下，只有非常少的神经元参与推理计算，整体效率及功耗都能得到很大的提升
- 训练模型时的梯度下降计算和权重更新，通过某种局部调度算法硬件固化的方式实现，且并不需要每个神经元都参与

从隐私保护角度来看，通过云服务承载人工智能计算并不是一个好的选择，因为用户的数据会被上传到云端，其间可能会被安全和滥用的担忧。依赖去中心化网络的人工智能计算，受制于安全计算上的额外开销和网络限制，应该也不会是首先选择的方案。所以，端侧人工智能硬件的发展（本地TPU计算）反而可能未来是与云计算并驾齐驱的不容忽视的主流方案。未来，由于两种环境下的智能计算在需求上差异明显，很可能云侧智能计算和端侧智能计算会以相似但并不完全相同的硬件技术架构各自发展出一套摩尔定律来。

光电混合计算也非常值得关注，因为光计算有着传统半导体集成电路所不能比拟的技术优势：
- 以光子为媒介的光计算设备非常适合线性计算（比如FMA）和信号传输
- 以电子为媒介的传统计算设备非常擅长非线性的逻辑计算

光电混合计算的主要挑战有两个：
- 需要光电转换和电光转换，这两个过程会带来额外的能耗、带宽和延迟上的挑战
- 光电混合计算能否像半导体制程工艺一样，发展成为大规模集成的光电混合芯片

> 未来智能计算的硬件架构，可能会和现在（以GPGPU为主流）非常不一样。

## 群体智能

生物智能的另一个特点是群体智能，群体智能是指一群个体通过相互作用和信息交流，从而产生的看似具有智能的集体行为。

群体智能的特点是：
- 群体智能的表现往往超过了单个个体的表现，群体智能的表现往往是非线性的
- 群体智能的表现往往是自组织的，没有中央控制，而是通过局部规则的简单调整来实现全局的复杂行为
- 群体智能的表现往往是适应性的，可以根据环境的变化来调整自己的行为

群体智能其实并不是一种罕见的现象，很多生物体都具有群体智能：
- 蚂蚁、蜜蜂这样的高度社会化分工的昆虫，是群体智能的典型代表，它们通过信息素的交流和行为的协调，实现了复杂的社会行为，比如寻找食物、建造巢穴、保卫领地等。
- 一些鱼类、鸟类等动物比昆虫具有更高的个体智能，但它们也是具有群体智能的，它们会通过集群行为来捕食、迁徙、保护自己等。
- 人类显然具有更加优秀的个体智能，但其实人类的智能同样具有一定的社会性，站在群体智能的角度来看，人类社会的发展也可以看成一种更加复杂的群体智能的体现。
- 如果我们把视角切换到到显微镜下，其实每个大脑皮层的神经元又何尝不是一个及其微小的智能单元，它们非常融洽的按照一定的分工自组织在一起，形成了人类大脑这样复杂的智能系统，这里同样也有群体智能的影子。

这种自组织的智能行为研究，虽然也衍生了不少最优化算法，但至今还没有深入影响到以LLM为代表的的人工智能技术的发展。- MoE架构里的多专家整合，看上去仿佛有一点群体智能的影子，但实际上这种整合是非常固定的模式，运作机制仍是非常原始和粗糙的，远远没有自适应的群体智能那么优雅。
- 无监督强化学习，看起来好像的确有一点自适应的味道了，但整个系统其实只有两个彼此对立的角色在博弈中进化，是在也称不上是群体智能算法

> 群体智能的研究，可能会为人工智能的发展带来新的思路和方法，不再是整体最优化，而是某种基于简单重复的自适应系统。

## 神秘的梦境

人类的大脑并不总是一直保持清醒，它需要睡眠来休息，然而我们对人类大脑在睡眠时发生了什么却知之甚少。比如在睡眠时，我们可能会产生梦境，梦境是一种非常神秘的现象，科学家们至今也没有完全弄清楚梦境的本质。梦境的特点是：
- 梦境是一种虚拟的体验，它是由大脑内部产生的，而不是由外部环境产生的
- 梦境往往是非常混乱的，它的内容可能是无序的、不连贯的
- 梦境往往是非常生动的，它的内容可能是非常真实的、具体的

虽然我们不一定会记住自己的梦境，但实际上大多数人睡眠时都会经常做梦，这一点是科学家们已经证实的。当整个生物神经网络不像清醒时，有那么多的输入信息需要处理，大脑会进入一种不同的工作状态。正所谓日有所思、也有所梦，这时的大脑在一些情绪性经历的刺激下，可能会自发产生一些模拟的输入信号，就像我们在一个仿真环境里让大脑皮层去经历一些有关联或相似但又未必不完整、凭空创造出来的片段。经历这些片段的同时，大脑并不是什么都不做，有时我们会神奇的发现一觉醒来，昨天刚学会的某种技能马上就有了明显的进步，这很可能是你的大脑皮层在睡眠是偷偷的加了一个班。就目前科学研究所得到的信息，睡眠时，大脑会对白天的信息进行整理和重塑，把重要的信息加强记忆，把不重要的信息减弱记忆，从而实现对信息的筛选和优化。梦境可能是大脑在整理信息的过程中产生的一种副产品。

站在人工智能的角度，最接近梦境的就是强化学习了，虽然看起来和睡眠或梦境并不一样。强化学习的训练过程，其实也是一种自我生成的过程，它的训练数据是自己生成的，而不是来自外部环境。我们可以把强化学习看成是一种自我生成的梦境。不过人类的睡眠和梦境还有很多秘密尚未揭开，人工智能可以直接借鉴的细节还是有限的。不过，至少我们能从侧面解释生成式人工智能的独特潜力和优势。具有生成能力的人工智能，相比较其它类型的算法模型，要更有机会通过自我强化的无监督学习过程获得智力的升级或能力的泛化。希望随着对人类睡眠机制的研究不断深入，我们可以更好的了解人类大脑强化学习的秘密，反过来促进人工智能的进一步发展。

> 现在没有特别成功的世界模型，所以我们还无法更直观的感受人工智能的“梦境”。

## 兴奋和抑制

人类大脑的神经元之间的连接是非常复杂的，神经元之间的连接不仅有兴奋的连接，还有抑制的连接。兴奋和抑制是大脑神经元之间信息传递的两种基本方式，它们在大脑的信息处理中起着非常重要的作用。

无论兴奋还是抑制，这些神经信号都是靠神经元之间的突触连接上的神经递质的扩散和吸收来实现的。神经递质的数量或浓度，包括扩散和吸收的速度，都要受物理规律和空间邻近性的制约，相当于不同神经元之间有彼此竞争的机制，相当于胜者对败者的抑制。

人工智能神经元的抑制性连接，主要有以下几种表达方式：
- 负权重（线性抑制）：类似抑制性突触，直接通过反向调节神经元输出，可能会阻止接收信号的神经元的激活
- 激活函数（非线性抑制）：不同激活函数都有自己的分布，可能会抑制过大或过小的信号传递
- 正则化（全局抑制）：对整个网络的激活进行抑制，惩罚过大的权重
- Dropout（局部抑制）：随机关闭一部分神经元，防止过拟合，也可以看成是一种冗余抑制机制
- 路由（动态抑制）：各种门控、竞争机制，可以动态调整神经元的激活，实现动态抑制

记得微软亚洲研究院曾发表过一篇关于三值神经网络的论文（BitNet 1.58b）。这个网络的特点是，神经元的激活值不是0或1，而是-1、0、1三个值。虽然论文的着眼点并非模拟抑制性连接，但跟非零即正或概率化的某些神经网络比，无疑是比较强化抑制性连接的。虽然站在数学的角度，浮点数、二进制还是对称三进制，都不会改变计算的本质，但这种比较强调抑制性连接的表达方式，可能会对神经网络的训练和泛化产生一定的影响。

生物智能里，抑制性连接和兴奋性连接的组合方式包括比例，应该包含一定的形态模式。尽管这些模式上的具体权重系后天习得，但先天基因可能早就为我们预设了很多基础图纸和限制。既然生物进化选择了抑制性神经网络，那么这种结构肯定是有它的优势和适应性的，也许深入挖掘会发现有意思的、更高效的神经网络。

> 探索训练时如何更高效的建立抑制性连接，可能也是有意思的技术方向。

## 协同进化

有一本很有趣的书，名字叫协同进化。虽然它的内容可能并不是专门为人工智能而写的，但其实对人工智能未来的发展形态也很有启发。人类、AI代理、AI模型就好像是在同一个生态环境里相互竞争又共存共荣的生物种群。
- 仅就眼下来说，如果人类突然小王，人工智能也会随之马上消失；而人工智能的出现和发展，也必然导致人类围绕着这个新技术的革命性的应用，而持续做出显著的调整和改变。
- Agent和LLM的关系也是如此。随着LLM向前进化，Agent的角色也会发生一些变化，有些功能或许会被LLM所取代，而另一些功能则会固化下来并得到增强；而Agent自身的工程技术进步，会促进AI应用落地并产生大量的需求反哺，这一定程度上也会影响LLM的发展方向，促使LLM站在更广阔的视角上去完成更复杂和更泛化的智能任务。

可预见的短期内，AI Agent作为人类、环境和LLM之间的媒介，是有着特殊的地位的：
- 站在AI伦理和安全的角度，只要Agent守好安全底线，就可以在发生风险时自动熔断，切断LLM与外部的关联，从而保护人类的安全
- 站在LLM发展的角度，Agent中可以通过一些工程技术手段，补充和完善那些那些受限于技术发展水平而LLM暂时还不具备的能力，促进AI应用的普及

> 人类、AI Agent、LLM之间的协同进化，可能是未来人工智能发展的趋势。

## 人工智能的局限性

我们对人工智能充满了无限的憧憬，但同时也有一种观点认为人工智能有很多的局限性：
- 情感：人工智能并没有真正意义的情感，它只是在无意识的模拟情感。
- 创造力：人工智能没有真正的创造力，它的生成式任务输出都是基于已有数据基础之上。
- 自我意识：人工智能只是像机器一样运行的一段程序，它并没有真正的自我意识。

我们无从判断这种观点是否具有实实在在的科学依据，抑或只是一种思辨式的哲学观点，甚至是受到了宗教信仰的裹挟。但是至少从目前人工智能的发展阶段来看，我们必须得承认当前的人工智能还有很多不足。不过站在自然科学或数学的角度看，无论情感、创造力还是自我意识，也都只是大脑皮层的一系列生化反应，同样是必须满足自然界的物理规律的，而这种满足自然规律的事物必然可以通过数学去精确的映射和模拟。这里并没有任何超自然的力量存在，所以人工智能最终也必然会具有这些能力（除非我们动用政治的力量去约定和规定这些能力只能为人类所独有）。

因此，几乎所有职业都面临巨大的变革甚至是威胁。从中短期看，人工智能很快会取代和补充的，主要是人类的“智能”部分（延伸到情感和创造力）。所以，在现有的社会制度与法律框架下，它暂时还不能取代与权力和责任相关的职业，比如：
- 它可以代替医生看胸片，提供明确诊断和指导处方，甚至代替外科医生做具体的手术操作，但它不能替人类医生在报告上签字
- 它可以帮律师查找案例和法律条文，甚至帮律师写诉状和辩护词，但它不能替代律师和法官在法庭上参与庭审辩论和判决

站在人类最顶端的非常依赖创造力的科研领域，人工智能可能也不会完全取代人类，而只是通过赋能提高效率。原因很简单，因为人类对科技创新的需求是无限大的。无论有多少人工智能，人类总是会有更多的问题需要解决，总是会有更多的事情需要创造。所以，在这些领域，人工智能最终可能会成为人类的一个重要工具，而不是彻底取代人类。当然，能够用好人工智能去解决实际问题的人，尤其是在科学技术上能有所突破者，其实是稀缺的，而且投入在科研上的资源也是有上限的，所以能吸纳的劳动者是很少的，不会成为主流。

另一个相对安全的职业，反而是门槛最低的低端体力工作，可能包括清洁工、服务员、搬运工等。这些工作虽然看起来简单，按说最容易被取代，但几次工业革命也都没有让它们消失。这可能是因为工作门槛很低，对应的人类工人成本也很低，我们很难有足够的动力去发明一种足够便宜的机器去彻底取代这些廉价的人类工人。

接下来谈谈几个大家关注度高的比较流行的职业（作为反例）：
- （传统）程序员：程序员是最容易被取代的（仅略好文案类工作）。首先，大多数传统程序员的工作，其实有着特别明确的目标和反馈信息，无外是写代码、写测试、看错误信息、尝试修改等等，这些工作都能从环境中得到非常明确的反馈信息，比如一些编译器错误输出、测试报告、线上服务的错误日志等等，机器学习非常擅长通过训练去解决这类目标和馈信息很明确的任务。其它目标不清晰、不太容易量化的行业就要困难一些。其次，程序员是很善于数字化的，比如Github就保存了大量价值很高的代码和其它数据，这些数据给了AI充足的训练语料，其它行业可能数字化程度低或规范性差，反倒缺乏足够的数据来让大模型在应付此类任务上达到足够高的水平。
- 教师：文科类教师的价值是冲击最大的，AI往往比普通人类教师知识渊博，而且能够提供更好的个性化教学；理科类教师也只是比文科教师略好一丝，但也很容易被取代；体育老师反倒是最不容易被AI取代的。教育工作者未来可能要把精力从专业知识的传授转移到情绪机制、社交指导、榜样引领、品格培养等方面，也就是把教书（留给AI）和育人（留给自己）分开。
- 文艺：无论是网络小说、短视频、动画建模、影视剧或是音乐和歌曲的创作，借助AIGC的力量，其参与门槛都会大大下降，不再需要掌握特定工具技能的专业人士，也不再需要大量的资金去启动项目或学习技能。可能像几十年前会计要会打算盘，现在要懂计算机一样，过渡期间会发生一些比较大的洗牌，但最终会有更多的人参与到这个行业中来，也会有更多的作品被创作出来，这是一个好事。

> 人工智能存在真正意义的局限么？或许只是我们对人工智能的认知还不够深入。
